{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27812,"status":"ok","timestamp":1703076417031,"user":{"displayName":"Salvatore Scalla","userId":"14753009183129779025"},"user_tz":-60},"id":"jN9Yfh0hJt6o","outputId":"39b2caf2-5f62-4f45-8392-00a840fc5407"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /gdrive\n","/gdrive/.shortcut-targets-by-id/1xOTFH12ejIcv2XhCAKusSYD6N-YChIUI/Homework 2\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/My\\ Drive/Homework 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gKQfMqWdJt6p"},"outputs":[],"source":["model_to_train = 'Singolo'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O2zn4754Jt6q"},"outputs":[],"source":["name = 'ResNet - 9/' + model_to_train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d-gKJX3MJt6q"},"outputs":[],"source":["# Fix randomness and hide warnings\n","seed = 42\n","\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","\n","import numpy as np\n","np.random.seed(seed)\n","\n","import logging\n","\n","import random\n","random.seed(seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4086,"status":"ok","timestamp":1703076421109,"user":{"displayName":"Salvatore Scalla","userId":"14753009183129779025"},"user_tz":-60},"id":"QAtKvfCnJt6s","outputId":"67aa3f00-6d58-4a33-e8ee-47e77c410107"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.15.0\n"]}],"source":["# Import tensorflow\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","tf.autograph.set_verbosity(0)\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R2whqFzKJt6s"},"outputs":[],"source":["import pandas as pd\n","import seaborn as sns\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","plt.rc('font', size=16)\n","from sklearn.preprocessing import MinMaxScaler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uXqMvnyiJt6u"},"outputs":[],"source":["def build_sequences(data, window_size=200, telescope=9, stride=1):\n","    \"\"\"\n","    Creates time windows for a given time series data.\n","\n","    Parameters:\n","    - data: numpy array, shape (n_samples,)\n","        The time series data.\n","    - window_size: int\n","        The size of the window.\n","    - telescope: int\n","        The number of timestamps to predict into the future.\n","    - stride: int, optional (default=1)\n","        The step size between consecutive windows.\n","\n","    Returns:\n","    - X: numpy array, shape (n_windows, window_size)\n","        The input features (windows of data).\n","    - y: numpy array, shape (n_windows, telescope)\n","        The target values corresponding to each window.\n","    \"\"\"\n","\n","    pad = 0\n","    n_windows = (len(data) - window_size - telescope) // stride + 1\n","\n","    if n_windows <= 0:\n","        # Time series is too short for the specified window size and future steps\n","        # Pad the time series with zeros at the beginning\n","        data = np.pad(data, (telescope + window_size - len(data), 0), 'constant', constant_values=pad)\n","        n_windows = 1\n","    else:\n","        to_add = stride + telescope + 1\n","        n_windows += 2\n","        data = np.pad(data, (to_add, 0), 'constant', constant_values=pad)\n","\n","    X = np.zeros((n_windows, window_size))\n","    y = np.zeros((n_windows, telescope))\n","\n","    j = 0\n","\n","    for i in range(0, n_windows * stride, stride):\n","        window = data[i:i+window_size]\n","        # Check if the window is not composed of all zeros\n","        if not np.all(window == 0):\n","            X[j, :] = window\n","            y[j, :] = data[i+window_size:i+window_size+telescope]\n","            j +=1\n","\n","    return X[:j], y[:j]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2lCAxJMPJt6v"},"outputs":[],"source":["def filter_timeseries(data, validity, min_valid_length, max_percentage = 0.1):\n","\n","    # Initialize an empty DataFrame for removed time series\n","    removed = 0\n","\n","    max_len = int(len(data) * max_percentage)\n","    mask = np.full(len(data), True)\n","\n","    # Iterate through each row in the input DataFrame\n","    for index in range(len(data)):\n","        # Find the start and end of the validity range for the current time series\n","        start_validity = validity[index][0]\n","        end_validity = validity[index][1]\n","\n","        # Calculate the length of the valid range for the current time series\n","        valid_length = end_validity - start_validity + 1\n","\n","        # Check if the valid length is greater than or equal to the specified minimum\n","        if removed < max_len and valid_length <= min_valid_length:\n","            mask[index] = False\n","            removed += 1\n","\n","        if removed >= max_len:\n","            return np.array(data[mask]), np.array(data[~mask])\n","\n","    return np.array(data[mask]), np.array(data[~mask])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jb5RQJAtJt6w"},"outputs":[],"source":["def build_train_test_datasets(dataset_by_categories, valid_by_categories, window = 200, telescope = 9 , stride = 10, max_percentage = 0.1):\n","\n","    X_train = {k : [] for k in dataset_by_categories.keys()}\n","\n","    y_train = {k : [] for k in dataset_by_categories.keys()}\n","\n","    X_test = {k : [] for k in dataset_by_categories.keys()}\n","\n","    y_test = {k : [] for k in dataset_by_categories.keys()}\n","\n","    for k in dataset_by_categories.keys():\n","\n","        training, testing = filter_timeseries(dataset_by_categories[k], valid_by_categories[k], 200, max_percentage=max_percentage)\n","\n","        for i, ts in enumerate(training):\n","            valid_start, valid_end = valid_by_categories[k][i]\n","\n","            v, l = build_sequences(ts[valid_start:valid_end, 0], window_size=window, stride=stride, telescope=telescope)#, debug=debug)\n","\n","            X_train[k].append(v)\n","            y_train[k].append(l)\n","\n","        X_train[k] = np.expand_dims(np.concatenate(X_train[k]), axis=2)\n","        y_train[k] = np.expand_dims(np.concatenate(y_train[k]), axis=2)\n","\n","        if(max_percentage != 0):\n","\n","            for i, ts in enumerate(testing):\n","                valid_start, valid_end = valid_by_categories[k][i]\n","\n","                v, l = build_sequences(ts[valid_start:valid_end, 0], window_size=window, stride=stride, telescope=telescope)#, debug = debug)\n","\n","                X_test[k].append(v)\n","                y_test[k].append(l)\n","\n","            X_test[k] = np.expand_dims(np.concatenate(X_test[k]), axis=2)\n","            y_test[k] = np.expand_dims(np.concatenate(y_test[k]), axis=2)\n","\n","    return X_train, y_train, X_test, y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mgH5XemSJt6x"},"outputs":[],"source":["def difference(data, valid_periods, interval=1):\n","    out = np.zeros_like(data)\n","\n","    for i in range(len(data)):\n","\n","        start, end = valid_periods[i]\n","\n","        ts = data[i][start:end]\n","\n","        out[i] [start+1:end] = np.diff(ts.T).T\n","\n","    return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tsm1LGZkJt6x"},"outputs":[],"source":["def invert_difference(data, diff_data, valid_periods = 'test', telescope=9):\n","\n","    inverted_data = diff_data.copy()\n","\n","    if valid_periods != 'test':\n","        for i in range(len(diff_data)):\n","            start, end = valid_periods[i]\n","            inverted_data[i][start:end] = np.expand_dims(np.concatenate(([data[i][start:end][0]], diff_data[i])).cumsum(), axis=1)[start:end]\n","\n","    else:\n","        for i in range(len(diff_data)):\n","            inverted_data[i] = np.expand_dims(np.concatenate((data[i][0], inverted_data[i]), axis = 0).cumsum(), axis=1)[1:, 0]\n","\n","    return inverted_data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lqRB5WMAJt6x"},"outputs":[],"source":["training_data = np.load('./training_dataset/training_data.npy')\n","categories = np.load('./training_dataset/categories.npy')\n","valid_periods = np.load('./training_dataset/valid_periods.npy')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":74,"status":"ok","timestamp":1703076468138,"user":{"displayName":"Salvatore Scalla","userId":"14753009183129779025"},"user_tz":-60},"id":"gUMrqKOHJt6x","outputId":"3c158158-fe72-4347-8091-486bd499212e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training data shape: (48000, 2776)\n","Categories shape: (48000,)\n","Valid periods shape: (48000, 2)\n"]}],"source":["print(\"Training data shape: {}\".format(training_data.shape))\n","print(\"Categories shape: {}\".format(categories.shape))\n","print(\"Valid periods shape: {}\".format(valid_periods.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":72,"status":"ok","timestamp":1703076468138,"user":{"displayName":"Salvatore Scalla","userId":"14753009183129779025"},"user_tz":-60},"id":"jpbpVV5lJt6y","outputId":"d71ae845-d5c1-4d51-e637-20b658dd9edb"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 48000 entries, 0 to 47999\n","Columns: 2776 entries, 0 to 2775\n","dtypes: float64(2776)\n","memory usage: 1016.6 MB\n"]}],"source":["training_df = pd.DataFrame(training_data)\n","training_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":71,"status":"ok","timestamp":1703076468139,"user":{"displayName":"Salvatore Scalla","userId":"14753009183129779025"},"user_tz":-60},"id":"NU0amY05Jt6y","outputId":"0461ea6a-a46a-49d7-e99e-2bb0d91cee20"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 48000 entries, 0 to 47999\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype\n","---  ------  --------------  -----\n"," 0   start   48000 non-null  int64\n"," 1   end     48000 non-null  int64\n","dtypes: int64(2)\n","memory usage: 750.1 KB\n"]}],"source":["valid_periods_df = pd.DataFrame(valid_periods, columns=('start', 'end'))\n","valid_periods_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69,"status":"ok","timestamp":1703076468139,"user":{"displayName":"Salvatore Scalla","userId":"14753009183129779025"},"user_tz":-60},"id":"HWlVu_3BJt6z","outputId":"80b1d04b-e335-4857-bedb-33d85183f7e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 48000 entries, 0 to 47999\n","Data columns (total 1 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   Category  48000 non-null  object\n","dtypes: object(1)\n","memory usage: 375.1+ KB\n"]}],"source":["categories_df = pd.DataFrame(categories, columns=('Category',))\n","categories_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QXFixtL8Jt6z"},"outputs":[],"source":["# Remove duplicated time series\n","\n","unique_mask = ~ training_df.duplicated()\n","training_data = training_data[unique_mask]\n","valid_periods = valid_periods[unique_mask]\n","categories = categories[unique_mask]\n","\n","training_data_df = pd.DataFrame(training_data)\n","valid_periods_df = pd.DataFrame(valid_periods, columns=(\"start\", \"end\"))\n","categories_df = pd.DataFrame(categories, columns=(\"Category\",))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"17CfmqwPJt6z"},"outputs":[],"source":["dataset_by_categories = {\n","    'A' : [],\n","    'B' : [],\n","    'C' : [],\n","    'D' : [],\n","    'E' : [],\n","    'F' : [],\n","}\n","\n","for category in np.unique(categories):\n","    dataset_by_categories[category] = np.array(training_data[categories == category])\n","    dataset_by_categories[category] = np.expand_dims(dataset_by_categories[category], axis=2)\n","\n","valid_by_categories = {\n","    'A' : [],\n","    'B' : [],\n","    'C' : [],\n","    'D' : [],\n","    'E' : [],\n","    'F' : [],\n","}\n","\n","for category in np.unique(categories):\n","    valid_by_categories[category] = np.array(valid_periods[categories == category])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66,"status":"ok","timestamp":1703076468139,"user":{"displayName":"Salvatore Scalla","userId":"14753009183129779025"},"user_tz":-60},"id":"3f_J1v8ZJt6z","outputId":"1c02cacc-9587-450f-fbe8-ae5f1b960638"},"outputs":[{"name":"stdout","output_type":"stream","text":["Minimum Time series length: 24\n","Maximum Time series length: 2776\n"]}],"source":["valid_periods_df['range'] = valid_periods_df[\"end\"] - valid_periods_df[\"start\"]\n","\n","print(\"Minimum Time series length: {}\".format(valid_periods_df['range'].min()))\n","print(\"Maximum Time series length: {}\".format(valid_periods_df['range'].max()))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65,"status":"ok","timestamp":1703076468140,"user":{"displayName":"Salvatore Scalla","userId":"14753009183129779025"},"user_tz":-60},"id":"lLy51SuMJt60","outputId":"bc7feb1e-58ca-4fc0-e107-c30abefad9f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["A\n","max range : 1943\n","min range : 46\n","mean range : 278.18034217877096\n","B\n","max range : 1484\n","min range : 42\n","mean range : 166.02269413051403\n","C\n","max range : 2708\n","min range : 42\n","mean range : 208.1937062937063\n","D\n","max range : 2641\n","min range : 42\n","mean range : 216.99860195725984\n","E\n","max range : 2776\n","min range : 42\n","mean range : 163.05896290895836\n","F\n","max range : 1068\n","min range : 24\n","mean range : 194.8303249097473\n"]}],"source":["min_range_by_category = {}\n","\n","for k in dataset_by_categories.keys():\n","    print(k)\n","    print(\"max range : {}\".format(valid_periods_df[categories == k][\"range\"].max()))\n","    min_range_by_category[k] = valid_periods_df[categories == k][\"range\"].min()\n","    print(\"min range : {}\".format(min_range_by_category[k]))\n","    print(\"mean range : {}\".format(valid_periods_df[categories == k][\"range\"].mean()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ehla5aTLJt60"},"outputs":[],"source":["test_size = 20\n","window = 200\n","stride = 5\n","telescope = 9"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"AxLh2OsFJt61"},"outputs":[],"source":["X_train, y_train, X_test, y_test = build_train_test_datasets(dataset_by_categories = dataset_by_categories,\n","                                                             valid_by_categories = valid_by_categories,\n","                                                             window=window,\n","                                                             telescope=telescope,\n","                                                             stride=stride,\n","                                                             max_percentage=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"a59SpNt32g71"},"outputs":[],"source":["X_acc = []\n","y_acc = []\n","\n","for k in X_train.keys():\n","  X_acc.append(X_train[k])\n","  y_acc.append(y_train[k])\n","\n","X_train = np.concatenate(X_acc)\n","y_train = np.concatenate(y_acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6buW0REnJt61"},"outputs":[],"source":["\n","def build_model(input_shape, output_shape):\n","    n_feature_maps = 64\n","\n","    #block 1\n","    input_layer = tfkl.Input(shape=(input_shape))\n","    input_layer = tfkl.Masking(mask_value=1.1)(input_layer) # serve mettere 1.1 come padding\n","\n","    x1 = input_layer\n","    conv_x = tfkl.Conv1D(n_feature_maps, 8, 1, padding='same')(input_layer)\n","    conv_x = tfkl.Activation('relu')(conv_x)\n","\n","    conv_y = tfkl.Conv1D(n_feature_maps, 5, 1, padding='same')(conv_x)\n","    conv_y = tfkl.Activation('relu')(conv_y)\n","\n","    conv_z = tfkl.Conv1D(n_feature_maps, 3, 1, padding='same')(conv_y)\n","\n","    is_expand_channels = not (input_shape[-1] == n_feature_maps)\n","    if is_expand_channels:\n","        x1 = tfkl.Conv1D(n_feature_maps, 1, 1,padding='same')(input_layer)\n","\n","    #Merging skip connection\n","    y = tfkl.Add()([x1, conv_z])\n","    y = tfkl.Activation('relu')(y)\n","\n","    #block 2\n","    x1 = y\n","    conv_x = tfkl.Conv1D(n_feature_maps*2, 8, 1, padding='same')(x1)\n","    conv_x = tfkl.Activation('relu')(conv_x)\n","\n","    conv_y = tfkl.Conv1D(n_feature_maps*2, 5, 1, padding='same')(conv_x)\n","    conv_y = tfkl.Activation('relu')(conv_y)\n","\n","    conv_z = tfkl.Conv1D(n_feature_maps*2, 3, 1, padding='same')(conv_y)\n","\n","    is_expand_channels = not (input_shape[-1] == n_feature_maps*2)\n","    if is_expand_channels:\n","        x1 = tfkl.Conv1D(n_feature_maps*2, 1, 1,padding='same')(x1)\n","\n","    #Merging skip connection\n","    y = tfkl.Add()([x1, conv_z])\n","    y = tfkl.Activation('relu')(y)\n","\n","    #block 3\n","    x1 = y\n","    conv_x = tfkl.Conv1D(n_feature_maps*2, 8, 1, padding='same')(x1)\n","    conv_x = tfkl.Activation('relu')(conv_x)\n","\n","    conv_y = tfkl.Conv1D(n_feature_maps*2, 5, 1, padding='same')(conv_x)\n","    conv_y = tfkl.Activation('relu')(conv_y)\n","\n","    conv_z = tfkl.Conv1D(n_feature_maps*2, 3, 1, padding='same')(conv_y)\n","\n","    is_expand_channels = not (input_shape[-1] == n_feature_maps*2)\n","    if is_expand_channels:\n","        x1 = tfkl.Conv1D(n_feature_maps*2, 1, 1,padding='same')(x1)\n","\n","    #Merging skip connection\n","    y = tfkl.Add()([x1, conv_z])\n","    y = tfkl.Activation('relu')(y)\n","\n","    full = tfkl.Flatten()(y)\n","\n","    # Classifier\n","    dropout = tfkl.Dropout(.5, seed=seed)(full)\n","\n","    # Add a final Convolution layer to match the desired output shape\n","    output_layer = tfkl.Dense(output_shape[0], activation = 'relu', name='output_layer')(dropout)\n","\n","    # Construct the model by connecting input and output layers\n","    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='CONV_LSTM_model')\n","\n","    # Compile the model with Mean Squared Error loss and Adam optimizer\n","    model.compile(loss=tf.keras.losses.MeanAbsoluteError(), optimizer=tf.keras.optimizers.Adam())\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"S-zkKR9cJt62"},"outputs":[],"source":["input_shape = X_train.shape[1:]\n","output_shape = y_train.shape[1:]\n","batch_size = 1024\n","epochs = 200\n","\n","callbacks = [\n","    tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=25, restore_best_weights=True),\n","    tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, factor=0.9, min_lr=1e-5)\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58,"status":"ok","timestamp":1703076468141,"user":{"displayName":"Salvatore Scalla","userId":"14753009183129779025"},"user_tz":-60},"id":"Bw3WKDxJJt62","outputId":"c238b048-fa62-4d33-be8d-6a6137b9b8e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"CONV_LSTM_model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_2 (InputLayer)        [(None, 200, 1)]             0         []                            \n","                                                                                                  \n"," conv1d (Conv1D)             (None, 200, 64)              576       ['input_2[0][0]']             \n","                                                                                                  \n"," activation (Activation)     (None, 200, 64)              0         ['conv1d[1][0]']              \n","                                                                                                  \n"," conv1d_1 (Conv1D)           (None, 200, 64)              20544     ['activation[1][0]']          \n","                                                                                                  \n"," activation_1 (Activation)   (None, 200, 64)              0         ['conv1d_1[1][0]']            \n","                                                                                                  \n"," conv1d_3 (Conv1D)           (None, 200, 64)              128       ['input_2[0][0]']             \n","                                                                                                  \n"," conv1d_2 (Conv1D)           (None, 200, 64)              12352     ['activation_1[1][0]']        \n","                                                                                                  \n"," add (Add)                   (None, 200, 64)              0         ['conv1d_3[1][0]',            \n","                                                                     'conv1d_2[1][0]']            \n","                                                                                                  \n"," activation_2 (Activation)   (None, 200, 64)              0         ['add[1][0]']                 \n","                                                                                                  \n"," conv1d_4 (Conv1D)           (None, 200, 128)             65664     ['activation_2[1][0]']        \n","                                                                                                  \n"," activation_3 (Activation)   (None, 200, 128)             0         ['conv1d_4[1][0]']            \n","                                                                                                  \n"," conv1d_5 (Conv1D)           (None, 200, 128)             82048     ['activation_3[1][0]']        \n","                                                                                                  \n"," activation_4 (Activation)   (None, 200, 128)             0         ['conv1d_5[1][0]']            \n","                                                                                                  \n"," conv1d_7 (Conv1D)           (None, 200, 128)             8320      ['activation_2[1][0]']        \n","                                                                                                  \n"," conv1d_6 (Conv1D)           (None, 200, 128)             49280     ['activation_4[1][0]']        \n","                                                                                                  \n"," add_1 (Add)                 (None, 200, 128)             0         ['conv1d_7[1][0]',            \n","                                                                     'conv1d_6[1][0]']            \n","                                                                                                  \n"," activation_5 (Activation)   (None, 200, 128)             0         ['add_1[1][0]']               \n","                                                                                                  \n"," conv1d_8 (Conv1D)           (None, 200, 128)             131200    ['activation_5[1][0]']        \n","                                                                                                  \n"," activation_6 (Activation)   (None, 200, 128)             0         ['conv1d_8[1][0]']            \n","                                                                                                  \n"," conv1d_9 (Conv1D)           (None, 200, 128)             82048     ['activation_6[1][0]']        \n","                                                                                                  \n"," activation_7 (Activation)   (None, 200, 128)             0         ['conv1d_9[1][0]']            \n","                                                                                                  \n"," conv1d_11 (Conv1D)          (None, 200, 128)             16512     ['activation_5[1][0]']        \n","                                                                                                  \n"," conv1d_10 (Conv1D)          (None, 200, 128)             49280     ['activation_7[1][0]']        \n","                                                                                                  \n"," add_2 (Add)                 (None, 200, 128)             0         ['conv1d_11[1][0]',           \n","                                                                     'conv1d_10[1][0]']           \n","                                                                                                  \n"," activation_8 (Activation)   (None, 200, 128)             0         ['add_2[1][0]']               \n","                                                                                                  \n"," flatten (Flatten)           (None, 25600)                0         ['activation_8[1][0]']        \n","                                                                                                  \n"," dropout (Dropout)           (None, 25600)                0         ['flatten[1][0]']             \n","                                                                                                  \n"," output_layer (Dense)        (None, 9)                    230409    ['dropout[1][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 748361 (2.85 MB)\n","Trainable params: 748361 (2.85 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["model = build_model(input_shape, output_shape)#, output_shape)\n","model.summary()\n","#tfk.utils.plot_model(model, expand_nested=True, show_shapes=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-fnIEh2kJt63","outputId":"222c2aeb-1bf7-4eaa-f430-ee472b1dcbf9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/200\n"," 60/481 [==>...........................] - ETA: 31s - loss: 0.1236"]}],"source":["# Train the model\n","\n","history = model.fit(\n","    x = X_train,\n","    y = y_train,\n","    batch_size = batch_size,\n","    epochs = epochs,\n","    validation_split=.1,\n","    callbacks = callbacks\n",").history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UwjQhAsGJt63"},"outputs":[],"source":["best_epoch = np.argmin(history['val_loss'])\n","plt.figure(figsize=(17,6))\n","plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n","plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n","plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n","plt.title('Mean Absolute Error')\n","plt.legend()\n","plt.grid(alpha=.3)\n","plt.show()\n","\n","plt.figure(figsize=(18,3))\n","plt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n","plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n","plt.legend()\n","plt.grid(alpha=.3)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sZnCT6rmJt64"},"outputs":[],"source":["# Predict the test set using the model\n","predictions = model.predict(X_test[model_to_train], verbose=0)\n","#predictions = predictions[:,:,0]\n","\n","# Print the shape of the predictions\n","print(f\"Predictions shape: {predictions.shape}\")\n","\n","# Calculate and print Mean Squared Error (MSE)\n","# MSE gives more weight to large errors due to squaring.\n","# It is useful when you want to penalize larger errors more heavily.\n","mean_squared_error = tfk.metrics.mean_squared_error(y_test[model_to_train].flatten(), predictions.flatten()).numpy()\n","print(f\"Mean Squared Error: {mean_squared_error}\")\n","\n","# Calculate and print Mean Absolute Error (MAE)\n","# MAE treats all errors equally, without giving extra weight to larger errors.\n","# It is useful when you want a metric that is less sensitive to outliers.\n","mean_absolute_error = tfk.metrics.mean_absolute_error(y_test[model_to_train].flatten(), predictions.flatten()).numpy()\n","print(f\"Mean Absolute Error: {mean_absolute_error}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zz0j6K58Jt64"},"outputs":[],"source":["def inspect_prediction(X, y, pred, telescope, idx=None):\n","    if(idx==None):\n","        idx=np.random.randint(0,len(X))\n","\n","    pred = np.concatenate([X[:,-1],pred],axis=1)\n","    y = np.concatenate([np.expand_dims(X[:,-1],axis=1),y],axis=1)\n","\n","    len_samples = len(X[0,:])\n","\n","    plt.figure(figsize=(12,5))\n","    plt.axvline(x=len_samples-1, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n","    plt.plot(np.arange(len_samples), X[idx,:], label = 'Given')\n","    plt.plot(np.arange(len_samples - 1, len_samples + telescope), y[idx,:], color='orange', label = 'Real')\n","    plt.plot(np.arange(len_samples - 1, len_samples + telescope), pred[idx,:], color='green', label = 'Predicted')\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H4Zpf5jmJt64"},"outputs":[],"source":["inspect_prediction(X_test[model_to_train], y_test[model_to_train], predictions, telescope=9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_IX2pRoJt65"},"outputs":[],"source":["model.save(\"./Models/\" + name)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}